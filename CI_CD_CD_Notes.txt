Q1. What is github actions?
Ans1. GitHub Actions is a feature of GitHub that allows you to automate various tasks in your software development workflow. 
It enables you to define custom workflows, which are sets of automated steps that can be triggered by events in your GitHub 
repository, such as pushing code, opening pull requests, or releasing a new version.

Key features of GitHub Actions include:
1. Workflow Automation: 
GitHub Actions allows you to automate various tasks, such as building and testing your code, deploying applications, or 
running linters and other code quality checks.

2. Event-Driven: 
Workflows can be triggered by events in your GitHub repository, such as pushes to specific branches, pull request creation or 
updates, issue comments, and more.

3. Docker Containers: 
Workflows can run in isolated Docker containers, ensuring a consistent and reproducible environment for your automation tasks.

4. Extensibility: 
GitHub Actions supports a wide range of pre-built actions that you can use in your workflows, and you can also create custom 
actions to suit your specific needs.

Using GitHub Actions, you can create efficient and automated CI/CD (Continuous Integration/Continuous Deployment) pipelines, 
reducing manual intervention and streamlining your development and release processes.

###################################################################################################################################

Q2. What is Docker?
Ans2. Docker is an open-source containerization platform by which you can pack your application and all its dependencies 
into a standardized unit called a container. Containers are light in weight which makes them portable and they are isolated 
from the underlying infrastructure and from each other container. 
You can run the docker image as a docker container in any machine where docker is installed without depending on the operating system.

Docker is popular because of the following:
1. Portability.
2. Reproducibility.
3. Efficiency.
4. Scalability.

###################################################################################################################################

Q3. What is Dockerfile?
Ans3. The Dockerfile uses DSL (Domain Specific Language) and contains instructions for generating a Docker image. 
Dockerfile will define the processes to quickly produce an image. While creating your application, you should create a Dockerfile 
in order since the Docker daemon runs all of the instructions from top to bottom.

It is a text document that contains necessary commands which on execution help assemble a Docker Image.

It is nothing but a text document containing a set of instructions and using those instructions we convert our application 
into docker image.

Set of Instructions in Dockerfile:
1. Install the python
2. Push the local/ current directory of application to app directory
3. Set this app directory as a working directory
4. install the requirements.txt file
5. Run the app.py file

###################################################################################################################################

Q4. What is Docker Image?
Ans4. It is a file, comprised of multiple layers, used to execute code in a Docker container. They are a set of instructions used to 
create docker containers. Docker Image is an executable package of software that includes everything needed to run an application. 
This image informs how a container should instantiate, determining which software components will run and how. 
Docker Container is a virtual environment that bundles application code with all the dependencies required to run the application. 
The application runs quickly and reliably from one computing environment to another.

Docker image is nothing but a compiled form of instruction which we have written in the dockerfile.

###################################################################################################################################

Q5. What is Docker Container?
Ans5. Docker container is a runtime instance of an image. Allows developers to package applications with all parts needed such as 
libraries and other dependencies. Docker Containers are runtime instances of Docker images. Containers contain the whole kit required 
for an application, so the application can be run in an isolated way. For eg.- Suppose there is an image of Ubuntu OS with 
NGINX SERVER when this image is run with the docker run command, then a container will be created and NGINX SERVER will be running on 
Ubuntu OS.

Docker container is nothing but a isolated system itself.
Inside this container, we can run the compiled image and whatever instructions which we have mentioned in the docker file will be 
executed.

###################################################################################################################################

Q6. What is Docker Hub?
Ans6. Docker Hub is a repository service and it is a cloud-based service where people push their Docker Container Images and also 
pull the Docker Container Images from the Docker Hub anytime or anywhere via the internet. Generally it makes it easy to find and 
reuse images. It provides features such as you can push your images as private or public registry where you can store and share Docker 
images

Mainly DevOps team uses the Docker Hub. It is an open-source tool and freely available for all operating systems. It is like storage 
where we store the images and pull the images when it is required. When a person wants to push/pull images from the Docker Hub they 
must have a basic knowledge of Docker. Let us discuss the requirements of the Docker tool.

###################################################################################################################################

Q7. What is Kubernetes?
Ans7. Kubernetes is an open-source Container Management tool that automates container deployment, container scaling, descaling, and 
container load balancing (also called a container orchestration tool). It is written in Golang and has a vast community because it 
was first developed by Google and later donated to CNCF (Cloud Native Computing Foundation). Kubernetes can group ‘n’ number of 
containers into one logical unit for managing and deploying them easily. It works brilliantly with all cloud vendors i.e. public, 
hybrid, and on-premises.

###################################################################################################################################

Q8. Explain in detail the below:
FROM python:3.8-slim-buster
WORKDIR /service
COPY requirements.txt .
COPY . ./
RUN pip install -r requirements.txt
ENTRYPOINT ["python3", "app.py"]

Ans8. Let's break down each step:

1. FROM python:3.8-slim-buster:

This line specifies the base image for the Docker container. In this case, it uses the official Python 3.8 image based on the 
Debian "Buster" (a codename for a Debian release) with a slim version. This image contains a minimal set of tools and libraries.

In short, slim-buster makes our container lighweight and easy to port.

2. WORKDIR /service:

This sets the working directory inside the container to "/service". Any subsequent commands will be executed in this directory.

3. COPY requirements.txt . (used to copy single file to working directory)"

Copies the requirements.txt file from the local directory (where the Dockerfile is located) to the /service directory 
inside the container. This file typically contains a list of Python packages and their versions required for the application.

4. COPY . ./ (used to copy all the files in the current directory to working directory):

Copies the contents of the local directory (where the Dockerfile is located) to the /service directory inside the container. 
This includes the application code and any other files needed for the application to run.

5. RUN pip install -r requirements.txt:

This command installs the Python dependencies listed in the requirements.txt file using the pip package manager. 
This step ensures that all required Python packages are available in the container.

6. ENTRYPOINT ["python3", "app.py"]:

Sets the default command to be executed when the container starts. In this case, it specifies that the Python script app.py 
should be run. The python3 command is used to execute the script.

## Explanation Summary:

The Dockerfile starts with a base Python image, sets the working directory, copies the requirements.txt file and application code 
into the container, installs the Python dependencies, and sets the default command to run the app.py script.

###############################################################################################################################

Q9. What are YAML files?
Ans9. YAML stands for Yet Another Markup Language.
YAML is often used for configuration files and data exchange between languages with different data structures.
Here we write configuration in the form key and value pair.

Here are some key features and characteristics of YAML:

1. Human-Readable: 
YAML is designed to be easy for humans to read and write. It uses indentation to represent the structure of data, similar to how 
Python uses indentation.

2. Whitespace-Sensitive: 
Indentation is significant in YAML to denote the structure of the data. Blocks of data at the same indentation level are 
considered part of the same structure.

3. Data Types: 
YAML supports various data types, including scalars (strings, numbers), sequences (arrays/lists), and mappings (key-value pairs). 
It can represent complex data structures in a concise and readable way.

4. Key-Value Pairs: 
YAML uses a simple syntax for key-value pairs, where the key and value are separated by a colon and are associated with each other.

5. Comments: 
YAML supports comments, which begin with the # symbol. Comments can be added at the end of a line or on their own line.